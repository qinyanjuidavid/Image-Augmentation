{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f976f3cf",
   "metadata": {},
   "source": [
    "### Increasing the Maize Leaf Disease Dataset Using Contrast Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292a09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import keras\n",
    "import pathlib\n",
    "import glob\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe01f9",
   "metadata": {},
   "source": [
    "## Steps\n",
    "- Loading the images and converting them into pixels.\n",
    "- Resizing and Rescaling.\n",
    "> Resizing involves making the images to be of same size and shape. Rescalling involves making the pixels to be in the range of 0-1.\n",
    "- Coming up with a pre-processing Layer.\n",
    "- Applying the pre-processing layer on the maize leaf disease dataset.\n",
    "- Training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12269a",
   "metadata": {},
   "source": [
    "### Task 1: Loading the images and converting them into pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac85307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir=pathlib.Path(os.getcwd()+\"/maize_leaf_diseases_dataset/data/\") # Windows Path\n",
    "data_list=list(glob.glob(f\"{data_dir}/*/*.jpg\",recursive=True)) # Getting all the images path\n",
    "print(len(data_list)) # Checking the length of our data\n",
    "\n",
    "with open(\"maize_images_pixels.txt\",\"w\") as writer: # Creating a text file\n",
    "    for imgPath in data_list: # Iterating through the list of image\n",
    "        img_pxls=cv2.imread(str(imgPath)) # Image to pixels\n",
    "        img=cv2.resize(img_pxls,(180,180))\n",
    "#             print(img_pxls.shape)\n",
    "#             print(img.shape)\n",
    "\n",
    "        imgName=os.path.basename(imgPath) # Getting image name\n",
    "        writer.write(f\"{imgName}\\n\\n{img_pxls}\\n\\n\") #Writin the image pixels in a text file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f916b02",
   "metadata": {},
   "source": [
    "### Labelling of the Maize Leaf Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816dc5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_labels_dict={\n",
    "    \"Blight\":0,\n",
    "    \"Common Rust\":1,\n",
    "    \"Gray Leaf Spot\":2,\n",
    "    \"Healthy\":3,\n",
    "}\n",
    "maize_leaf_dict={\n",
    "    \"Blight\":list(glob.glob(f\"{data_dir}/Blight/*.jpg\")),\n",
    "    \"Common Rust\":list(glob.glob(f\"{data_dir}/Common_Rust/*.jpg\")),\n",
    "    \"Gray Leaf Spot\":list(glob.glob(f\"{data_dir}/Gray_Leaf_Spot/*.jpg\")),\n",
    "    \"Healthy\":list(glob.glob(f\"{data_dir}/Healthy/*.jpg\")),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184c89b",
   "metadata": {},
   "source": [
    "### Loading the images and turning image to pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49afd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=[],[]\n",
    "for maize_name,images in maize_leaf_dict.items():\n",
    "    for image in images:\n",
    "        img=cv2.imread(str(image))#Convert image to pixels\n",
    "        resized_img=cv2.resize(img,(180,180))#Images to be of same size\n",
    "        x.append(resized_img)#Pixels\n",
    "        y.append(maize_labels_dict[maize_name])#Label Random 0,1,2,3\n",
    "#     print(x[0])\n",
    "#     print(y[:5])\n",
    "x=np.array(x) #Pixels stored in numpy array\n",
    "y=np.array(y) #Labels stored in numpy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2297d",
   "metadata": {},
   "source": [
    "### Training, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03afb13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3139\n",
      "1047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train, y_test=train_test_split(x,y,random_state=0)\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "x_train_scaled=x_train/255\n",
    "x_test_scaled=x_test/255\n",
    "#Scale\n",
    "print(x_train_scaled[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f714815",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=4 #Blight(0),Common Rust(1),Gray Leaf Spot(2),Healthy(3)\n",
    "#Building the model CNN\n",
    "#Activation function helps in predictions\n",
    "model=Sequential([\n",
    "    # \n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),#Relu is our standard activation layer | applied 16 filters of 3 X 3 Matrix\n",
    "    layers.MaxPooling2D(), # Reduce the size of the output by selecting the maximum value to increase computational speed \n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(), #2D array\n",
    "    layers.Flatten(), # Flatten our values, the dense layer accepts a 1D array\n",
    "    #128 neourons--> try and error\n",
    "    layers.Dense(128,activation=\"relu\"), #Dense perform matrix-vector multiplication\n",
    "    layers.Dense(num_classes) #if 0 neuron is activated it means its Blight, no activation(linear activation)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c7e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #exit value is 4\n",
    "              #loss-->exit value\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "105b69dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 55s 543ms/step - loss: 0.5938 - accuracy: 0.7646\n",
      "Evaluate\n",
      "33/33 [==============================] - 6s 158ms/step - loss: 0.5470 - accuracy: 0.7861\n",
      "[[-1.7987967e-02 -1.5862657e+00 -5.8196443e-01  2.0177455e+00]\n",
      " [ 7.5370936e+00  1.8968250e+01  3.1816006e+00 -1.7378855e+01]\n",
      " [ 4.9515910e+00  2.6652369e+00  3.3730206e+00 -3.8650494e+00]\n",
      " ...\n",
      " [ 8.0318898e-02 -1.3762819e+00 -6.2900716e-01  1.9197729e+00]\n",
      " [ 5.7251792e+00  3.9352148e+00  4.5431533e+00 -5.9637847e+00]\n",
      " [ 7.6732254e+00  1.7796471e+01  5.3091598e+00 -1.8433516e+01]]\n",
      "tf.Tensor([0.10598596 0.02208788 0.06029988 0.8116264 ], shape=(4,), dtype=float32)\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: <module 'keras.api._v2.keras.layers.experimental.preprocessing' from 'C:\\\\Users\\\\User\\\\anaconda3\\\\lib\\\\site-packages\\\\keras\\\\api\\\\_v2\\\\keras\\\\layers\\\\experimental\\\\preprocessing\\\\__init__.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39margmax(score))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_test[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m data_augmentation\u001b[38;5;241m=\u001b[39m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(x[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:134\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    132\u001b[0m   layers \u001b[38;5;241m=\u001b[39m [layers]\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m--> 134\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:175\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    173\u001b[0m     layer \u001b[38;5;241m=\u001b[39m functional\u001b[38;5;241m.\u001b[39mModuleWrapper(layer)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe added layer must be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    176\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man instance of class Layer. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    177\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(layer))\n\u001b[0;32m    179\u001b[0m tf_utils\u001b[38;5;241m.\u001b[39massert_no_legacy_layers([layer])\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n",
      "\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <module 'keras.api._v2.keras.layers.experimental.preprocessing' from 'C:\\\\Users\\\\User\\\\anaconda3\\\\lib\\\\site-packages\\\\keras\\\\api\\\\_v2\\\\keras\\\\layers\\\\experimental\\\\preprocessing\\\\__init__.py'>"
     ]
    }
   ],
   "source": [
    "\n",
    "#Update the weights in the network based on the input \n",
    "model.fit(x_train_scaled,y_train,epochs=1)\n",
    "#Helps to determine whether the data is over trained or not\n",
    "# Evaluate\n",
    "print(\"Evaluate\")\n",
    "model.evaluate(x_test_scaled,y_test)\n",
    "# Predictions\n",
    "prediction=model.predict(x_test_scaled)\n",
    "print(prediction)\n",
    "#Convert to probability score\n",
    "score=tf.nn.softmax(prediction[0])\n",
    "print(score)\n",
    "print(np.argmax(score))\n",
    "print(y_test[0])\n",
    "data_augmentation=Sequential([\n",
    "    layers.experimental.preprocessing\n",
    "])\n",
    "plt.axis('off')\n",
    "plt.imshow(x[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
